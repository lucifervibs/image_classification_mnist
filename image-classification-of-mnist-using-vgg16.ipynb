{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019248,
     "end_time": "2020-10-13T16:04:55.456974",
     "exception": false,
     "start_time": "2020-10-13T16:04:55.437726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-13T16:04:55.504321Z",
     "iopub.status.busy": "2020-10-13T16:04:55.503658Z",
     "iopub.status.idle": "2020-10-13T16:05:01.625879Z",
     "shell.execute_reply": "2020-10-13T16:05:01.625183Z"
    },
    "papermill": {
     "duration": 6.149223,
     "end_time": "2020-10-13T16:05:01.626024",
     "exception": false,
     "start_time": "2020-10-13T16:04:55.476801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 20:02:30.369914: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-17 20:02:30.570814: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-17 20:02:30.571798: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-17 20:02:31.684013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries completed.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm # for progress bar\n",
    "\n",
    "# Libraries for TensorFlow\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow import keras\n",
    "\n",
    "# Library for Transfer Learning\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "print(\"Importing libraries completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021721,
     "end_time": "2020-10-13T16:05:01.669566",
     "exception": false,
     "start_time": "2020-10-13T16:05:01.647845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Data Gethering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset from keras\n",
    "\n",
    "(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "# Verifying dataset\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)\n",
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Processing data to make it compitable with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 84), (10000, 28, 84))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the images into 3 channels as MNIST images are Black and White so have 1 channel\n",
    "\n",
    "xtrain=np.dstack([xtrain] * 3)\n",
    "xtest=np.dstack([xtest]*3)\n",
    "xtrain.shape,xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape images as per the tensor format required by tensorflow\n",
    "\n",
    "xtrain = xtrain.reshape(-1, 28,28,3)\n",
    "xtest= xtest.reshape (-1,28,28,3)\n",
    "xtrain.shape,xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize the images 48*48 as required by VGG16\n",
    "\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "\n",
    "xtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\n",
    "xtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n",
    "#train_x = preprocess_input(x)\n",
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:01.718764Z",
     "iopub.status.busy": "2020-10-13T16:05:01.718154Z",
     "iopub.status.idle": "2020-10-13T16:05:01.736975Z",
     "shell.execute_reply": "2020-10-13T16:05:01.736356Z"
    },
    "papermill": {
     "duration": 0.046787,
     "end_time": "2020-10-13T16:05:01.737085",
     "exception": false,
     "start_time": "2020-10-13T16:05:01.690298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
      "['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
      "['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
      "Zero\n"
     ]
    }
   ],
   "source": [
    "# # listing the folders containing images\n",
    "\n",
    "# preparing array that can be used later\n",
    "\n",
    "class_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "print(class_names)\n",
    "\n",
    "val_class_names =['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "print(val_class_names)\n",
    "\n",
    "test_class_names=['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine']\n",
    "print(test_class_names)\n",
    "\n",
    "# Function to know the name of the element\n",
    "\n",
    "def Get_Element_Name(argument):\n",
    "    switcher = {\n",
    "        0: \"Zero\",\n",
    "        1: \"One\",\n",
    "        2: \"Two\",\n",
    "        3: \"Three\",\n",
    "        4: \"Four\",\n",
    "        5: \"Five\",\n",
    "        6: \"Six\",\n",
    "        7: \"Seven\",\n",
    "        8: \"Eight\",\n",
    "        9: \"Nine\",\n",
    "    }\n",
    "    return switcher.get(argument, \"Invalid\")\n",
    "\n",
    "print(Get_Element_Name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021448,
     "end_time": "2020-10-13T16:05:01.77993",
     "exception": false,
     "start_time": "2020-10-13T16:05:01.758482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Dataset Completed.\n"
     ]
    }
   ],
   "source": [
    "# Preparing data\n",
    "\n",
    "x=[] # to store array value of the images\n",
    "x=xtrain\n",
    "y=[] # to store the labels of the images\n",
    "y=ytrain\n",
    "\n",
    "test_images=[]\n",
    "test_images=xtest\n",
    "test_images_Original=[]\n",
    "test_images_Original=xtest\n",
    "test_image_label=[] # to store the labels of the images\n",
    "test_image_label=ytest\n",
    "\n",
    "val_images=[]\n",
    "val_images=xtest\n",
    "val_images_Original=[]\n",
    "val_images_Original=xtest\n",
    "val_image_label=[] # to store the labels of the images\n",
    "val_image_label=ytest # to store the labels of the images\n",
    "\n",
    "print(\"Preparing Dataset Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022629,
     "end_time": "2020-10-13T16:05:32.630009",
     "exception": false,
     "start_time": "2020-10-13T16:05:32.60738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Verification of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:32.716961Z",
     "iopub.status.busy": "2020-10-13T16:05:32.716062Z",
     "iopub.status.idle": "2020-10-13T16:05:33.40521Z",
     "shell.execute_reply": "2020-10-13T16:05:33.4062Z"
    },
    "papermill": {
     "duration": 0.740868,
     "end_time": "2020-10-13T16:05:33.406362",
     "exception": false,
     "start_time": "2020-10-13T16:05:32.665494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "(60000, 48, 48, 3)\n",
      "(60000, 10)\n",
      "Test Dataset\n",
      "(10000, 48, 48, 3)\n",
      "(10000, 10)\n",
      "Validation Dataset\n",
      "(10000, 48, 48, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Verifying the output\n",
    "\n",
    "# Training Dataset\n",
    "print(\"Training Dataset\")\n",
    "\n",
    "x=np.array(x) # Converting to np arrary to pass to the model\n",
    "print(x.shape)\n",
    "\n",
    "y=to_categorical(y) # onehot encoding of the labels\n",
    "# print(y)\n",
    "print(y.shape)\n",
    "\n",
    "# Test Dataset\n",
    "print(\"Test Dataset\")\n",
    "\n",
    "test_images=np.array(test_images) \n",
    "print(test_images.shape)\n",
    "\n",
    "test_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\n",
    "print(test_image_label.shape)\n",
    "\n",
    "# Validation Dataset\n",
    "print(\"Validation Dataset\")\n",
    "\n",
    "val_images=np.array(val_images) \n",
    "print(val_images.shape)\n",
    "\n",
    "val_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\n",
    "print(val_image_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029412,
     "end_time": "2020-10-13T16:05:33.471421",
     "exception": false,
     "start_time": "2020-10-13T16:05:33.442009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Building a Model: Using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:33.533749Z",
     "iopub.status.busy": "2020-10-13T16:05:33.533004Z",
     "iopub.status.idle": "2020-10-13T16:05:44.598209Z",
     "shell.execute_reply": "2020-10-13T16:05:44.597604Z"
    },
    "papermill": {
     "duration": 11.104106,
     "end_time": "2020-10-13T16:05:44.598378",
     "exception": false,
     "start_time": "2020-10-13T16:05:33.494272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of default VGG16 model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 20:02:57.015037: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-06-17 20:02:58.767118: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Check properties of the model that we are going to use for Transfer Learning\n",
    "\n",
    "print(\"Summary of default VGG16 model.\\n\")\n",
    "\n",
    "# we are using VGG16 for transfer learnin here. So we have imported it\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# initializing model with weights='imagenet'i.e. we are carring its original weights\n",
    "model_vgg16=VGG16(weights='imagenet')\n",
    "\n",
    "# display the summary to see the properties of the model\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064954,
     "end_time": "2020-10-13T16:05:44.729494",
     "exception": false,
     "start_time": "2020-10-13T16:05:44.66454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Observations:**\n",
    "1. We want to carry weights as it was in original model, so we are carring weights = 'imagenet'\n",
    "2. The very first layer is input layer which accept image size = (224, 224, 3). Our image size are different, so we need to change the parameter - image_size in the first layer. Our size will be: (224,224, 3)\n",
    "3. We want to change the last layer as we have 10 class classificatoin problem. So, we will not include top layer\n",
    "4. Also, we will not train all the layers except the last one as we will have to train that. So, we will set properties for trainable = False excet for the top i.e. last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:44.869684Z",
     "iopub.status.busy": "2020-10-13T16:05:44.867997Z",
     "iopub.status.idle": "2020-10-13T16:05:45.67772Z",
     "shell.execute_reply": "2020-10-13T16:05:45.676814Z"
    },
    "papermill": {
     "duration": 0.884855,
     "end_time": "2020-10-13T16:05:45.677847",
     "exception": false,
     "start_time": "2020-10-13T16:05:44.792992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelling WITH Transfer Learning\n",
    "\n",
    "# Here we will prepare model as per our requirements\n",
    "\n",
    "print(\"Summary of Custom VGG16 model.\\n\")\n",
    "print(\"1) We setup input layer and 2) We removed top (last) layer. \\n\")\n",
    "\n",
    "# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (224,224,3)\n",
    "input_layer=layers.Input(shape=(48,48,3))\n",
    "\n",
    "# initialize the transfer model VGG16 with appropriate properties per our need.\n",
    "# we are passing paramers as following\n",
    "# 1) weights='imagenet' - Using this we are carring weights as of original weights.\n",
    "# 2) input_tensor to pass the VGG16 using input_tensor\n",
    "# 3) we want to change the last layer so we are not including top layer\n",
    "model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n",
    "\n",
    "# See the summary of the model with our properties.\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062235,
     "end_time": "2020-10-13T16:05:45.803276",
     "exception": false,
     "start_time": "2020-10-13T16:05:45.741041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "1. The first layer is having image size = (224,224,3) now as we defined.\n",
    "1. Also, see the folloiwng 2 top (last) layers which were there in original VGG16 are now not the part of our customized layer because we set include_top=False:\n",
    "\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 4096)              102764544 \n",
    "_________________________________________________________________\n",
    "fc2 (Dense)                  (None, 4096)              16781312  \n",
    "_________________________________________________________________\n",
    "predictions (Dense)          (None, 1000)              4097000     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:45.937409Z",
     "iopub.status.busy": "2020-10-13T16:05:45.936405Z",
     "iopub.status.idle": "2020-10-13T16:05:45.97485Z",
     "shell.execute_reply": "2020-10-13T16:05:45.976206Z"
    },
    "papermill": {
     "duration": 0.11057,
     "end_time": "2020-10-13T16:05:45.976396",
     "exception": false,
     "start_time": "2020-10-13T16:05:45.865826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# access the current last layer of the model and add flatten and dense after it\n",
    "\n",
    "print(\"Summary of Custom VGG16 model.\\n\")\n",
    "print(\"1) We flatten the last layer and added 1 Dense layer and 1 output layer.\\n\")\n",
    "\n",
    "last_layer=model_vgg16.output # we are taking last layer of the model\n",
    "\n",
    "# Add flatten layer: we are extending Neural Network by adding flattn layer\n",
    "flatten=layers.Flatten()(last_layer) \n",
    "\n",
    "# Add dense layer\n",
    "dense1=layers.Dense(100,activation='relu')(flatten)\n",
    "dense1=layers.Dense(100,activation='relu')(flatten)\n",
    "dense1=layers.Dense(100,activation='relu')(flatten)\n",
    "\n",
    "\n",
    "# Add dense layer to the final output layer\n",
    "output_layer=layers.Dense(10,activation='softmax')(flatten)\n",
    "\n",
    "# Creating modle with input and output layer\n",
    "model=models.Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:46.115318Z",
     "iopub.status.busy": "2020-10-13T16:05:46.114333Z",
     "iopub.status.idle": "2020-10-13T16:05:46.13057Z",
     "shell.execute_reply": "2020-10-13T16:05:46.130994Z"
    },
    "papermill": {
     "duration": 0.089633,
     "end_time": "2020-10-13T16:05:46.131138",
     "exception": false,
     "start_time": "2020-10-13T16:05:46.041505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will freez all the layers except the last layer\n",
    "\n",
    "# we are making all the layers intrainable except the last layer\n",
    "print(\"We are making all the layers intrainable except the last layer. \\n\")\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:46.263057Z",
     "iopub.status.busy": "2020-10-13T16:05:46.262341Z",
     "iopub.status.idle": "2020-10-13T16:05:47.304388Z",
     "shell.execute_reply": "2020-10-13T16:05:47.303577Z"
    },
    "papermill": {
     "duration": 1.110035,
     "end_time": "2020-10-13T16:05:47.304567",
     "exception": false,
     "start_time": "2020-10-13T16:05:46.194532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)\n",
    "# print(xtrain)\n",
    "# print(xtest)\n",
    "# print(ytrain)\n",
    "# print(ytest)\n",
    "\n",
    "print(\"Splitting data for train and test completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:47.447838Z",
     "iopub.status.busy": "2020-10-13T16:05:47.446897Z",
     "iopub.status.idle": "2020-10-13T16:05:47.455266Z",
     "shell.execute_reply": "2020-10-13T16:05:47.455994Z"
    },
    "papermill": {
     "duration": 0.086702,
     "end_time": "2020-10-13T16:05:47.456199",
     "exception": false,
     "start_time": "2020-10-13T16:05:47.369497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiling Model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(\"Model compilation completed.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:05:47.598576Z",
     "iopub.status.busy": "2020-10-13T16:05:47.595596Z",
     "iopub.status.idle": "2020-10-13T16:06:43.14505Z",
     "shell.execute_reply": "2020-10-13T16:06:43.144411Z"
    },
    "papermill": {
     "duration": 55.62044,
     "end_time": "2020-10-13T16:06:43.145196",
     "exception": false,
     "start_time": "2020-10-13T16:05:47.524756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the Model\n",
    "\n",
    "# xtrain2=xtrain.reshape(60000,48,48,3)\n",
    "# xtest2=xtest.reshape(10000,48,48,3)\n",
    "\n",
    "history = model.fit(xtrain,ytrain,epochs=20,batch_size=128,verbose=True,validation_data=(xtest,ytest))\n",
    "\n",
    "print(\"Fitting the model completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.125478,
     "end_time": "2020-10-13T16:06:43.397199",
     "exception": false,
     "start_time": "2020-10-13T16:06:43.271721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:06:43.667235Z",
     "iopub.status.busy": "2020-10-13T16:06:43.666583Z",
     "iopub.status.idle": "2020-10-13T16:06:43.670691Z",
     "shell.execute_reply": "2020-10-13T16:06:43.670228Z"
    },
    "papermill": {
     "duration": 0.148805,
     "end_time": "2020-10-13T16:06:43.670787",
     "exception": false,
     "start_time": "2020-10-13T16:06:43.521982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function helps to predict individual image supplied to it\n",
    "\n",
    "# Function 1\n",
    "\n",
    "def predict(img_name):\n",
    "    img=image.load_img(img_name,target_size=(48,48))\n",
    "    img=image.img_to_array(img)\n",
    "    plt.imshow(img.astype('int32'))\n",
    "    plt.show()\n",
    "    img=preprocess_input(img)\n",
    "\n",
    "    prediction=model.predict(img.reshape(1,48,48,3))\n",
    "    output=np.argmax(prediction)\n",
    "\n",
    "    print(class_names[output] + \": \" + Get_Element_Name(class_names[output]))\n",
    "\n",
    "    \n",
    "# Function 2\n",
    "\n",
    "# This function plots the image supplied in array\n",
    "def plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n",
    "    \n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img.astype('int32'))\n",
    "    \n",
    "    predicted_label=np.argmax(predictions_array)\n",
    "    true_label=np.argmax(true_label)\n",
    "\n",
    "    if predicted_label == true_label: #setting up label color\n",
    "        color='green' # correct then blue colour\n",
    "    else:\n",
    "        color='red' # wrong then red colour\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% \\n ({})\".format(Get_Element_Name(predicted_label), \n",
    "                                            100*np.max(predictions_array), Get_Element_Name(true_label), \n",
    "                                            color=color, horizontalalignment='left'))\n",
    "        \n",
    "        \n",
    "#     plt.xlabel(\"{} {:2.0f}% ({})\".format(val_class_names[predicted_label], \n",
    "#                                          100*np.max(predictions_array), val_class_names[true_label]), \n",
    "#                                          color=color)\n",
    "\n",
    "\n",
    "# Function 3\n",
    "\n",
    "# This function plots bar chart supplied in the array data\n",
    "def plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predicted_label=np.argmax(predictions_array)\n",
    "    true_label=np.argmax(true_label)\n",
    "\n",
    "    if predicted_label == 0:\n",
    "        predicted_label=1\n",
    "    if true_label == 0:\n",
    "        true_label=1\n",
    "    \n",
    "    thisplot=plt.bar(range(10), predicted_label, color='seashell')\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.134982,
     "end_time": "2020-10-13T16:06:43.932453",
     "exception": false,
     "start_time": "2020-10-13T16:06:43.797471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:06:44.195274Z",
     "iopub.status.busy": "2020-10-13T16:06:44.194412Z",
     "iopub.status.idle": "2020-10-13T16:06:45.580572Z",
     "shell.execute_reply": "2020-10-13T16:06:45.579959Z"
    },
    "papermill": {
     "duration": 1.521324,
     "end_time": "2020-10-13T16:06:45.580696",
     "exception": false,
     "start_time": "2020-10-13T16:06:44.059372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing prediction arrary\n",
    "predictions=[]\n",
    "\n",
    "for img in tqdm(val_images):\n",
    "    img=img.reshape(1,48,48,3)\n",
    "    predictions.append(model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:06:45.858858Z",
     "iopub.status.busy": "2020-10-13T16:06:45.848962Z",
     "iopub.status.idle": "2020-10-13T16:06:51.529722Z",
     "shell.execute_reply": "2020-10-13T16:06:51.528912Z"
    },
    "papermill": {
     "duration": 5.820452,
     "end_time": "2020-10-13T16:06:51.529883",
     "exception": false,
     "start_time": "2020-10-13T16:06:45.709431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction of individual images taken from internet\n",
    "\n",
    "# call the function\n",
    "\n",
    "# defining parameters to pass to function\n",
    "i=random.randrange(1, 10000) # image number 12. You may change value of i for play around\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "# we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n",
    "# which is preprocessed as VGG16 process and used for prediction.\n",
    "plot_image(i,predictions, val_image_label, val_images_Original) \n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, val_image_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:06:51.827288Z",
     "iopub.status.busy": "2020-10-13T16:06:51.825943Z",
     "iopub.status.idle": "2020-10-13T16:06:54.311808Z",
     "shell.execute_reply": "2020-10-13T16:06:54.312299Z"
    },
    "papermill": {
     "duration": 2.638431,
     "end_time": "2020-10-13T16:06:54.312433",
     "exception": false,
     "start_time": "2020-10-13T16:06:51.674002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declaring variables\n",
    "num_rows=5\n",
    "num_cols=5\n",
    "num_images=num_rows*num_cols\n",
    "\n",
    "plt.figure(figsize=(2*2*num_cols,2*num_rows))\n",
    "\n",
    "print(\"Classification of using Transfer Learning (VGG16)\\n\")\n",
    "print(\"Predicted, Percentage, (Original)\\n\")\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    ii=random.randrange(1,10000)\n",
    "    # we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n",
    "    # which is preprocessed as VGG16 process and used for prediction.\n",
    "    plot_image(ii,predictions, val_image_label, val_images_Original)\n",
    "    \n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "\n",
    "    plot_value_array(i, predictions, val_image_label)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and accuracy\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-13T16:06:54.639371Z",
     "iopub.status.busy": "2020-10-13T16:06:54.638631Z",
     "iopub.status.idle": "2020-10-13T16:06:54.645163Z",
     "shell.execute_reply": "2020-10-13T16:06:54.644241Z"
    },
    "papermill": {
     "duration": 0.170744,
     "end_time": "2020-10-13T16:06:54.645302",
     "exception": false,
     "start_time": "2020-10-13T16:06:54.474558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Notebook completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
